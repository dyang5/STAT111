\newpage

\section{Joint and Conditional Distributions}

\subsection{Multivariate Normal}

\begin{enumerate}[a)]
    \item A random vector $\mathbf{X} = (X_1, \dots, X_k)$ is said to have a Multivariate Normal (MVN) distribution if every
    linear combination of the $X_j$ follows a Normal distribution. That is,
    \[
        t_1 X_1 + \dots + t_k X_k 
    \]
    follows a Normal distribution for any choice of constants $t_1, \dots, t_k$. \\

    [Add why this allows for vectors that do not have a proper joint density function]

    \item If $\mathbf{Y} \sim N_n(\mu, \mathbf{V})$, then the joint PDF for $\mathbf{y} = (y_1, \dots, y_n)$ is
    \[
        f_{\mathbf{Y}}(\mathbf{y}) = \frac{\exp \left[ -\frac{1}{2}(\mathbf{y} -\mathbf{\mu})^T \mathbf{V}^{-1} (\mathbf{y} - \mathbf{\mu}) \right]}{\sqrt{(2\pi )^n |\det \mathbf{V}|}}
    \]

    Explain how this matches the bivariate Normal density of presentation 3(a). 

    \item Suppose that $V$ is block diagonal; without loss of generality, we can assume that
    \[
        \mathbf{V} = \begin{bmatrix}
            \mathbf{V}_1 & 0 \\
            0 & \mathbf{V}_2  \\
        \end{bmatrix}.
    \]
    
    By properties of block matrices, we know that $\det \mathbf{V} = (\det \mathbf{V}_1)(\det \mathbf{V}_2)$. Furthermore, 
    \[
        \mathbf{V}^{-1} = \begin{bmatrix}
            \mathbf{V}_1 & 0 \\
            0 & \mathbf{V}_2  \\
        \end{bmatrix}^{-1}
        = \begin{bmatrix}
            \mathbf{V}_1^{-1} &  0\\
            0 & \mathbf{V}_2^{-1} \\
        \end{bmatrix}
    \]
    Suppose that $Y_1 \sim N_{n_1}(\mathbf{\mu}_1, \mathbf{V}_1)$ and $Y_2 \sim N_{n_2}(\mathbf{\mu}_2, \mathbf{V}_2)$, where $n_1 + n_2 = n$, $\mathbf{\mu}_1$ and $\mathbf{\mu}_2$ form $\mathbf{\mu}$ of $Y$, and similarly, $\mathbf{V}_1$ and $\mathbf{V}_2$ form $\mathbf{V}$. 
    Note that
    \[
        \exp \left[ -\frac{1}{2}(\mathbf{y} -\mathbf{\mu})^T \mathbf{V}^{-1} (\mathbf{y} - \mathbf{\mu}) \right] = 
        \exp \left[ -\frac{1}{2}(\mathbf{y}_1 -\mathbf{\mu}_1)^T \mathbf{V_1}^{-1} (\mathbf{y}_1 - \mathbf{\mu}_1) \right] \cdot \exp \left[ -\frac{1}{2}(\mathbf{y}_2 -\mathbf{\mu}_2)^T \mathbf{V_2}^{-1} (\mathbf{y}_2 - \mathbf{\mu}_2) \right].
    \]
    Furthermore, 
    \[
        \sqrt{(2\pi )^n |\det \mathbf{V}|} = \sqrt{(2\pi )^{n_1 + n_2} |\det \mathbf{V_1} \det \mathbf{V}_2|}.
    \]
    It follows that
    \begin{align*}
        f_{\mathbf{Y}}(\mathbf{y}) &= \frac{\exp \left[ -\frac{1}{2}(\mathbf{y} -\mathbf{\mu})^T \mathbf{V}^{-1} (\mathbf{y} - \mathbf{\mu}) \right]}{\sqrt{(2\pi )^n |\det \mathbf{V}|}} \\
        &= \frac{\exp \left[ -\frac{1}{2}(\mathbf{y}_1 -\mathbf{\mu}_1)^T \mathbf{V_1}^{-1} (\mathbf{y}_1 - \mathbf{\mu}_1) \right]}{\sqrt{(2\pi )^{n_1} |\det \mathbf{V_1}|}}
        \frac{\exp \left[ -\frac{1}{2}(\mathbf{y}_2 -\mathbf{\mu}_2)^T \mathbf{V_2}^{-1} (\mathbf{y}_2 - \mathbf{\mu}_2) \right]}{\sqrt{(2\pi )^{n_2} |\det \mathbf{V_2}|}} \\
        &= f_{\mathbf{Y}_1}(\mathbf{y}_1)f_{\mathbf{Y}_2}(\mathbf{y}_2)
    \end{align*}
    where $\mathbf{Y}_1$ and $\mathbf{Y}_2$ are two independent sub-vectors of $\mathbf{Y}$.
\end{enumerate}